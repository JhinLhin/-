# ByteByteGo

## 05 Design A Rate Limiter

> ------
>
> ## 第一步：澄清需求（开场必做！）
>
> > 面试一开始，先问问题，别急着设计。这显示你思路清晰。
>
> 你说：
>
> > "在开始设计之前，我想先确认几个问题——"
>
> **要问的问题：**
>
> | 问题                           | 为什么问           |
>| ------------------------------ | ------------------ |
> | 是客户端限流还是服务端限流？   | 方向完全不同       |
>| 按什么限流？IP？用户ID？       | 影响数据结构设计   |
> | 系统规模多大？                 | 决定是否需要分布式 |
> | 需要在分布式环境下工作吗？     | 影响架构复杂度     |
> | 限流器是独立服务还是嵌入代码？ | 部署方式不同       |
> | 被限流的用户需要收到通知吗？   | 影响响应设计       |
> 
> **得到的答案（标准版）：**
> 
> - 服务端限流
>- 支持灵活规则（IP、用户ID都要支持）
> - 大规模系统，需要分布式
>- 设计决定由你来做
> - 需要通知用户
> 
> ------
> 
> ## 第二步：说出核心需求
>
> > 把需求总结出来，让面试官点头确认。
>
> **功能需求：**
>
> - 准确限制超额请求
>- 用户被限流时要收到清晰提示
> 
>**非功能需求：**
> 
> - 低延迟（不能拖慢正常请求）
>- 内存占用小
> - 支持分布式（多台服务器共享限流状态）
>- 高容错（限流器挂了不能影响主系统）
> 
> ------
> 
> ## 第三步：高层设计
>
> ### 3.1 先说"放在哪里"
>
> > 这是第一个设计决策，要主动提出来。
>
> **三个选项：**
>
> **① 放在客户端** ❌
>
> - 客户端代码可以被恶意用户篡改，不安全
>- 我们控制不了客户端实现
> 
>**② 放在服务器代码里** ✅ 可以
> 
> - 完全控制算法
>- 但每个服务都要自己实现，重复工作多
> 
>**③ 放在中间件（API Gateway）** ✅ 推荐
> 
> - 独立的一层，客户端请求先经过它再到服务器
>- 还可以顺便做：SSL、身份验证、IP白名单
> - 微服务架构下最常用
>
> > **面试金句：** "我推荐将限流器实现为中间件，这样可以与业务逻辑解耦，并且在微服务架构中可以统一管理。"
> 
> ------
>
> ### 3.2 介绍算法（重要！）
>
> > 说"我知道有几种算法，让我分析一下各自的优缺点"
>
> #### 算法一：Token Bucket（令牌桶）⭐ 最常用
>
> **直觉理解：** 想象一个桶，系统每秒往里放N个令牌。每来一个请求，取一个令牌。桶空了就拒绝请求。
>
> **关键参数：**
>
> - 桶容量（burst size）：最多能存多少令牌
>- 补充速率：每秒放多少令牌
> 
>**特点：** 允许短时间突发流量（桶里有存货就能用）
> 
> ✅ 优点：实现简单、内存效率高、允许突发
> ❌ 缺点：两个参数难以调优
> 
>> **使用公司：** Amazon、Stripe
> 
> ------
>
> #### 算法二：Leaking Bucket（漏桶）
>
> **直觉理解：** 请求先进队列排队，系统以固定速率处理队列。队列满了就丢弃新请求。
>
> **特点：** 输出速率固定，像水从桶底漏出去一样均匀
>
> ✅ 优点：输出稳定，适合需要均匀处理的场景
> ❌ 缺点：突发流量会塞满队列，新请求会被丢弃
> 
>> **使用公司：** Shopify
> 
> ------
>
> #### 算法三：Fixed Window Counter（固定窗口计数）
>
> **直觉理解：** 把时间切成固定格子（比如每分钟一格），每格独立计数。超过上限就拒绝。
>
> **致命缺陷：** 窗口边界问题——如果允许每分钟5个请求，用户可以在00:59发5个，01:01再发5个，实际上1秒内发了10个！
>
> ✅ 优点：简单、内存高效
> ❌ 缺点：边界处可能放过双倍流量
> 
>------
> 
> #### 算法四：Sliding Window Log（滑动窗口日志）
>
> **直觉理解：** 记录每个请求的精确时间戳。每次新请求来时，只统计"最近1分钟"内的请求数量（滑动的窗口，不是固定格子）。
>
> **流程：**
>
> 1. 删除1分钟前的旧时间戳
>2. 添加当前时间戳
> 3. 如果日志大小 ≤ 上限，放行；否则拒绝
>
> ✅ 优点：非常精确，任意滑动窗口内都不超额
>  ❌ 缺点：**内存消耗大**（被拒绝的请求时间戳也要存）
> 
>------
> 
> #### 算法五：Sliding Window Counter（滑动窗口计数）⭐ 推荐
>
> **直觉理解：** 结合了固定窗口的低内存 + 滑动窗口的精确性。
>
> **公式：**
>
> ```
>当前窗口请求数 + 上一窗口请求数 × 当前时间点在本窗口的百分比
> ```
>
> **例子：** 限制每分钟7个请求。上一分钟5个，当前分钟3个，现在处于当前分钟的30%位置：
> 
> ```
>3 + 5 × 70% = 6.5 → 取整为6，未超限，放行
> ```
>
> ✅ 优点：平滑处理突发、内存高效
>  ❌ 缺点：是近似值，极端情况下有误差（但Cloudflare测试显示误差率仅0.003%）
> 
>------
> 
> #### 算法对比表
>
> | 算法                   | 内存   | 精确度   | 允许突发 | 推荐场景       |
>| ---------------------- | ------ | -------- | -------- | -------------- |
> | Token Bucket           | 低     | 中       | ✅        | 通用，最常用   |
>| Leaking Bucket         | 低     | 中       | ❌        | 需要稳定输出   |
> | Fixed Window           | 最低   | 低       | 看情况   | 简单场景       |
> | Sliding Window Log     | **高** | **最高** | ❌        | 精确度要求极高 |
> | Sliding Window Counter | 低     | 高       | 部分     | 分布式推荐     |
> 
> ------
> 
> ### 3.3 高层架构图
>
> > 说完算法后，画出基本架构
>
> **核心问题：计数器存哪里？**
>
> - ❌ 数据库（MySQL）：磁盘读写太慢
>- ✅ **Redis（内存缓存）**：极快，支持原子操作
> 
>**Redis的两个关键命令：**
> 
> - `INCR`：计数器 +1
>- `EXPIRE`：设置过期时间（窗口结束自动清零）
> 
>**基本流程：**
> 
> ```
>客户端 → 限流中间件 → (查询Redis计数器) → API服务器
>                           ↑
>                         Redis
> ```
> 
> 1. 客户端发请求到限流中间件
> 2. 中间件去Redis查对应的计数器
> 3. 未超限 → 转发给API服务器，同时Redis计数+1
>4. 已超限 → 返回 **HTTP 429** (Too Many Requests)
> 
> ------
> 
> ## 第四步：深入设计
>
> > 面试官这时会追问细节，或者你主动提出
>
> ### 4.1 限流规则存哪里？
>
> 规则写在**配置文件**里（YAML格式），存在磁盘上：
>
> ```yaml
>domain: auth
> descriptors:
>  - key: auth_type
>     value: login
>     rate_limit:
>       unit: minute
>       requests_per_unit: 5  # 每分钟最多登录5次
> ```
> 
> **工作流程：** Workers（后台程序）定期从磁盘读取规则 → 存入**Cache（缓存）**→ 限流中间件从缓存读（速度快）
> 
> ------
>
> ### 4.2 如何通知用户被限流？
>
> **HTTP响应头（Response Headers）：**
>
> | Header                    | 含义                 |
>| ------------------------- | -------------------- |
> | `X-Ratelimit-Remaining`   | 当前窗口还剩几次请求 |
>| `X-Ratelimit-Limit`       | 每个窗口最多几次     |
> | `X-Ratelimit-Retry-After` | 多少秒后可以重试     |
> 
> 被限流时返回：**429 Too Many Requests** + `X-Ratelimit-Retry-After`
> 
> ------
>
> ### 4.3 分布式环境下的挑战
>
> > 这是面试最爱考的部分！主动提出来显得很厉害
>
> **挑战一：Race Condition（竞争条件）**
>
> **问题：** 两个服务器同时读到Redis计数器=3，都以为自己是第4个请求，都写回4，实际应该是5！
>
> **解决方案：**
>
> - 使用 **Lua Script**（Redis原生支持的脚本，读+写是原子操作，不会被打断）
>- 使用 **Redis的sorted sets**（有序集合，支持原子操作）
> 
>> **面试金句：** "我们可以用Lua Script来保证读-检查-写的原子性，避免竞争条件。"
> 
> ------
>
> **挑战二：Synchronization（同步问题）**
>
> **问题：** 多台限流服务器，每台都有自己的计数。用户今天请求了限流器1，明天请求了限流器2，两台不共享数据，限流形同虚设！
>
> **错误方案：** Sticky Session（让同一用户永远打到同一台服务器）→ 不灵活、不可扩展
>
> **正确方案：** 所有限流器共享同一个 **集中式Redis**
>
> ```
>限流器1 ──→ Redis（共享）
> 限流器2 ──→       ↑
>```
> 
> ------
> 
> ### 4.4 性能优化
>
> **优化一：多数据中心 + 边缘节点**
>
> - 用户请求路由到**最近的边缘服务器**，减少延迟
>- Cloudflare在全球有194个边缘节点
> 
>**优化二：最终一致性（Eventual Consistency）**
> 
> - 多个Redis节点之间不需要强一致，允许短暂数据差异
>- 牺牲少量精确度，换取极大的性能提升
> 
>------
> 
> ### 4.5 完整详细架构
>
> ```
>客户端
>   ↓
>限流中间件
>   ├── 读取缓存中的规则
>   ├── 查询Redis计数器
>   │
>   ├── 未超限 → API服务器（处理请求）
>   │              → 更新Redis计数器
>   │
>   └── 已超限 → 返回429
>                ↓ (可选)
>             消息队列（稍后重试）
> 
> 后台：Workers定期从磁盘读规则 → 更新Cache
> ```
> 
> ------
> 
> ## 第五步：监控
>
> > 设计完了要说"我们还需要监控"，显示你考虑周全
>
> - 监控**规则是否有效**：如果太多合法请求被拒，规则太严了
>- 监控**算法是否有效**：如果突发流量时系统崩溃，可能需要换Token Bucket
> - 收集被限流请求的统计数据，定期调整参数
>
> ------
> 
> ## 面试金句汇总
>
> | 时机       | 说什么                                                       |
>| ---------- | ------------------------------------------------------------ |
> | 开始       | "在设计之前，我想澄清几个需求..."                            |
>| 选架构位置 | "我推荐将限流器作为中间件，与业务解耦"                       |
> | 存储选择   | "数据库太慢，我们用Redis——它支持原子操作且有过期机制"        |
> | 算法选择   | "对于分布式系统，我推荐滑动窗口计数，它在内存效率和精确度间取得了很好的平衡" |
> | 分布式挑战 | "在分布式环境下有两个主要挑战：竞争条件和同步问题"           |
> | 竞争条件   | "用Lua Script保证原子性"                                     |
> | 同步问题   | "所有限流器共享集中式Redis"                                  |
> | 收尾       | "我们还需要监控系统来验证规则有效性并持续优化"               |
> 
> ------
> 
> ## 一句话记忆法
>
> > **"中间件 + Redis + 滑动窗口 = 限流三件套；分布式两坑：Race Condition用Lua解，同步用集中式Redis解"**

# Hello Interview

## FB News Feed

> 

## Rate Limiter 

> ------
>
> ## 🧠 先理解：Rate Limiter 是什么？
>
> **Rate Limiter（限流器）** = API 的保安。
>
> 你的服务器就像一家餐厅，每分钟只能服务 100 个人。如果来了 200 个人，保安（Rate Limiter）就会挡住后 100 个，说"对不起，人满了，等一会儿再来"。
>
> 技术上：每个用户每分钟最多发 100 个请求 → 超过了就返回 **HTTP 429 Too Many Requests**。
>
> ------
>
> ## 第一步：需求确认（Requirements）
>
> > 面试一开始，**先问需求，不要直接设计**。这显示你有工程思维。
>
> ### 你要说的话：
>
> "在开始设计之前，我想先确认几个问题……"
>
> ### 功能需求（Functional Requirements）
>
> | 需求         | 说明                                                     |
> | ------------ | -------------------------------------------------------- |
> | 识别客户端   | 通过 User ID / IP / API Key 区分谁在发请求               |
> | 限制请求     | 根据可配置的规则限流，比如"每分钟 100 次"                |
> | 拒绝超限请求 | 返回 HTTP 429，附带有用的 headers 告诉客户端啥时候能重试 |
>
> ### 非功能需求（Non-Functional Requirements）
>
> | 需求          | 说明                                  |
> | ------------- | ------------------------------------- |
> | 低延迟        | 每次限流检查 < 10ms，不能拖慢正常请求 |
> | 高可用        | 限流服务挂了不能让整个 API 崩         |
> | 高并发        | 支持 **100万请求/秒**，1亿日活用户    |
> | 最终一致性 OK | 不同节点之间允许短暂的限流数据不同步  |
>
> ------
>
> ## 第二步：核心实体（Core Entities）
>
> > 面试中快速过，1分钟搞定
>
> ```
> Rule（规则）     → 定义"谁" 在"什么接口"能发"多少"请求
>                    例：普通用户 1000次/小时，搜索接口 10次/分钟
> 
> Client（客户端） → 被限流的对象，可以是 User ID / IP / API Key
> 
> Request（请求）  → 进来的 HTTP 请求，携带客户端身份和时间戳
> ```
>
> **三者关系**：Request 进来 → 识别 Client → 查找适用的 Rule → 决定放行还是拒绝
>
> ------
>
> ## 第三步：系统接口（System Interface）
>
> > 面试中一句话定义核心 API
>
> ```
> isRequestAllowed(clientId, ruleId) 
> → { allowed: boolean, remaining: number, resetTime: timestamp }
> ```
>
> 这个返回值对应响应头：
>
> - `X-RateLimit-Remaining: 5`（还剩几次）
> - `X-RateLimit-Reset: 1700000000`（啥时候重置）
> - `Retry-After: 60`（多少秒后重试）
>
> ------
>
> ## 第四步：高层设计（High-Level Design）
>
> ### 🏠 先解决：Rate Limiter 放在哪里？
>
> > 这是面试第一个关键决策点，你要对比三个方案
>
> ------
>
> #### 方案一：In-Process（每个服务器自己限流）
>
> **直觉理解**：每个服务器自己记"这个用户来了多少次"。
>
> **问题**：你有 5 台服务器，用户发了 100 个请求，每台看到 20 个，每台都觉得"没超限"，放行。但实际上用户发了 100 个！
>
> ❌ 无法在多台服务器之间共享状态，**根本不能用于分布式系统**。
>
> ------
>
> #### 方案二：Dedicated Service（独立的限流微服务）
>
> **直觉理解**：专门开一家"审批公司"，所有服务器的请求都先去审批公司问"这个用户能过吗"。
>
> **优点**：全局状态统一，逻辑灵活
>
> **问题**：每个请求都要额外发一次网络请求给审批公司，**增加延迟**。还有单点故障风险。
>
> ⚠️ 可用，但有成本。
>
> ------
>
> #### 方案三：API Gateway（在网关层限流）✅ 我们选这个
>
> **直觉理解**：在大门口放保安，进门前就检查，不让超限的人进来。应用服务器根本不用管。
>
> **优点**：
>
> - 请求进不来就被拒，不消耗后端资源
> - 所有流量天然经过网关，天然集中
> - 无需额外网络跳转（相比方案二）
>
> **限制**：只能看到 HTTP 请求里的信息（headers、IP 等），看不到业务逻辑
>
> ✅ **这是生产环境最常用方案，我们选这个。**
>
> ------
>
> ### 🪪 如何识别客户端？
>
> | 标识符     | 使用场景        | 来源                              |
> | ---------- | --------------- | --------------------------------- |
> | User ID    | 已登录用户      | JWT Token（Authorization header） |
> | IP Address | 未登录/公开 API | X-Forwarded-For header            |
> | API Key    | 开发者 API      | X-API-Key header                  |
>
> **实际系统会叠加多层规则**，取最严格的：
>
> ```
> Alice 个人限制: 1000次/小时  (还剩 500次)
> Alice 的 IP 限制: 100次/分钟  (已用完!)
> → 结果：Alice 被拦截（因为 IP 这条触发了）
> ```
>
> ------
>
> ### ⚙️ 核心算法：选哪种限流算法？
>
> > 这是面试最核心的技术讨论，你要能讲清楚所有算法再说选哪个
>
> ------
>
> #### 算法一：Fixed Window Counter（固定窗口计数器）
>
> **类比**：时钟整点重置的停车计时器。12:00到12:59 是一个格，最多停 100 辆车。
>
> **实现**：用 hash 表，`用户ID:时间窗口开始时间 → 计数器`
>
> ```
> alice:12:00:00 = 100  ← 满了
> alice:12:01:00 = 5    ← 新格子
> ```
>
> **致命缺陷**：边界突破攻击！
>
> ```
> 12:00:59 发 100 个请求 ✅（第一个格子最后一秒）
> 12:01:00 发 100 个请求 ✅（第二个格子第一秒）
> → 2秒内发了 200 个请求，但都没被拦截！
> ```
>
> ❌ 简单但有安全漏洞
>
> ------
>
> #### 算法二：Sliding Window Log（滑动窗口日志）
>
> **类比**：记录每次停车的精确时间戳，检查时看"过去 60 分钟内"有几条记录。
>
> **优点**：完全精确，无边界问题
>
> **问题**：每个用户需要存储所有请求的时间戳。100万用户 × 1000次/小时 = **存储爆炸**
>
> ❌ 内存太贵，不适合大规模
>
> ------
>
> #### 算法三：Sliding Window Counter（滑动窗口计数器）
>
> **类比**：用"当前格子"和"上一个格子"的数据，按比例估算过去 60 秒的请求数。
>
> **公式**：`估算请求数 = 上个窗口计数 × (1 - 已过去的比例) + 当前窗口计数`
>
> **例子**：
>
> ```
> 当前时刻：12:01:45（在12:01:00-12:01:59窗口内，已过75%）
> 上个窗口(12:00) 有 80 个请求
> 当前窗口(12:01) 有 30 个请求
> 
> 估算 = 80 × (1 - 0.75) + 30 = 20 + 30 = 50个请求
> ```
>
> ✅ 内存省（只需两个计数器），近似精确，是很好的折中
>
> ------
>
> #### 算法四：Token Bucket（令牌桶）✅ 我们选这个
>
> **类比（关键！记住这个）**：
>
> > 想象一个桶，系统不断往里加水（令牌）。你每次请求就舀一瓢水。桶满了多余的水溢出（令牌不超过上限）。桶空了就不能舀水（请求被拒）。
>
> | 概念                    | 类比       | 作用              |
> | ----------------------- | ---------- | ----------------- |
> | Bucket（桶）            | 水桶       | 允许短暂突发      |
> | Token（令牌）           | 水         | 每次请求消耗 1 个 |
> | Refill Rate（补充速率） | 水龙头速度 | 控制长期速率      |
> | Capacity（容量）        | 桶的大小   | 控制最大突发量    |
>
> **例子**：
>
> ```
> 桶容量: 100 tokens（最多存 100 个）
> 补充速率: 10 tokens/分钟
> 
> 用户可以先冲一波发 100 个请求（突发）
> 然后每分钟最多发 10 个（平稳）
> ```
>
> **每个用户只需存储**：`(当前token数, 上次补充时间)` → 内存极省
>
> ✅ **Stripe 等大公司都用这个。支持突发流量，内存高效，实现简洁。我们选它。**
>
> ------
>
> ### 🗄️ 状态存在哪里？引入 Redis
>
> > 这是高频面试考点，必须讲清楚
>
> **问题**：我们有多个 API Gateway 实例，每个用户的令牌桶状态必须共享，不然每个 Gateway 各自计数，结果不准。
>
> **答案：Redis**
>
> **Redis 是什么（给小白）**：Redis 就是一个超快的、存在内存里的"共享字典"。所有 Gateway 都去这个字典里读写用户的令牌桶状态。速度 < 1ms。
>
> **操作流程**：
>
> ```
> 1. 请求到达 Gateway A，用户是 Alice
> 2. Gateway 读取 Redis: alice:bucket → { tokens: 50, last_refill: 10:00:00 }
> 3. 计算应该补充多少 tokens（根据时间差）
> 4. 原子更新 Redis：写入新的 token 数和时间戳
> 5. token > 0 → 放行；token = 0 → 返回 429
> ```
>
> **Redis 存储的数据**：
>
> ```
> alice:bucket = {
>   tokens: 50,
>   last_refill: 1700000000
> }
> ```
>
> 设置 1小时 TTL（过期自动删除），防止内存泄漏。
>
> ------
>
> ### ⚠️ 竞态条件问题及解决
>
> > 面试加分点，主动提出这个问题
>
> **问题**：两个 Gateway 同时读取 Alice 的桶，都看到 1 个 token，都认为可以放行，都让请求通过。但实际上只有 1 个 token，应该只允许 1 个请求！
>
> **解决方案：Lua 脚本**
>
> **Lua 脚本是什么**：Redis 支持在服务器端运行小程序（Lua脚本）。整个"读取 → 计算 → 写入"在 Redis 里**原子执行**，不会被其他操作打断。
>
> ```lua
> -- 伪代码
> local tokens = redis.get(key)
> local new_tokens = calculate(tokens, current_time)
> if new_tokens > 0 then
>   redis.set(key, new_tokens - 1)
>   return "ALLOW"
> else
>   return "DENY"
> end
> ```
>
> 一个原子操作 = 没有竞态条件 ✅
>
> ------
>
> ## 第五步：深度讨论（Deep Dives）
>
> > 主动引导面试官讨论这些话题，展示你考虑了扩展性
>
> ------
>
> ### Deep Dive 1：如何支撑 100万请求/秒？
>
> **问题**：单个 Redis 实例只能处理约 10万-20万次操作/秒，但我们需要处理 100万请求/秒（每次限流需要多次 Redis 操作），远超上限。
>
> **解决方案：Redis 分片（Sharding）**
>
> **分片是什么（给小白）**：把数据分散到多个 Redis 实例上，每个实例负责一部分用户。就像图书馆的书分 A-G、H-M、N-Z 三个区，找书时先去对应区。
>
> **如何分配用户到哪个分片：一致性哈希（Consistent Hashing）**
>
> **一致性哈希是什么**：对用户 ID（或 IP）做哈希运算，结果决定去哪个 Redis 实例。重要特性：同一个用户**永远**去同一个实例（保证状态一致），加减实例时只有少量用户需要迁移。
>
> ```
> hash(alice) % 10 = 3  → 去 Redis 实例 #3
> hash(bob)   % 10 = 7  → 去 Redis 实例 #7
> ```
>
> **结果**：10 个 Redis 实例 × 10万次/秒 = 100万次/秒 ✅
>
> **生产实践**：直接用 **Redis Cluster**（Redis 官方集群方案），它自动做分片，不需要你手动写哈希路由逻辑。
>
> ------
>
> ### Deep Dive 2：Redis 挂了怎么办？高可用
>
> **两种故障处理策略**：
>
> | 策略                        | 行为                     | 适用场景                       |
> | --------------------------- | ------------------------ | ------------------------------ |
> | **Fail-Open（开放失败）**   | Redis 挂了就放行所有请求 | 宁可流量泄漏，不能服务中断     |
> | **Fail-Closed（关闭失败）** | Redis 挂了就拒绝所有请求 | 宁可服务中断，不能失去限流保护 |
>
> **我们选 Fail-Closed（关闭失败）**
>
> 原因：对于社交媒体平台，Redis 经常在流量高峰时出问题。如果这时 Fail-Open 放行所有请求，海量流量涌入后端，会导致**级联崩溃**（cascade failure）——限流器故障变成全站崩溃，更糟糕。
>
> **如何减少 Redis 故障：主从复制（Master-Replica）**
>
> **主从复制是什么**：每个 Redis 分片有一个主节点（Master）负责读写，有一个或多个从节点（Replica）实时同步数据。主节点挂了，从节点自动升级为新主节点。Redis Cluster 内置这个功能，自动故障转移。
>
> ```
> Redis Shard 1: [Master] ← 同步 → [Replica]
>                 ↑ 挂了          ↑ 自动升为 Master
> ```
>
> ------
>
> ### Deep Dive 3：如何降低延迟？
>
> | 优化手段                                | 原理                                                | 效果                                 |
> | --------------------------------------- | --------------------------------------------------- | ------------------------------------ |
> | **连接池（Connection Pooling）**        | 提前建好一批 TCP 连接，请求来了直接用，不用每次握手 | 省去 TCP 握手的 20-50ms              |
> | **地理分布（Geographic Distribution）** | 在不同地区部署 Redis，用户就近访问                  | 北京用户不用连美国，延迟从 150ms→5ms |
> | **Lua 脚本合并操作**                    | 把读+算+写合并成一次 Redis 调用                     | 减少网络往返次数                     |
>
> > 面试中：重点说**连接池**和**地理分布**，其他的"如果面试官追问再展开"。
>
> ------
>
> ### Deep Dive 4：热点问题（Hot Key）
>
> **什么是热点**：某个用户/IP 产生极大量请求，导致负责它的那个 Redis 分片被压垮，而其他分片很闲。
>
> **合法来源**：企业级 API 客户、大型数据爬虫、手机 App 频繁刷新 **恶意来源**：DDoS 攻击、机器人刷接口
>
> **应对策略**：
>
> | 场景         | 策略                                                         |
> | ------------ | ------------------------------------------------------------ |
> | 合法高频用户 | 提供高级套餐（更高限额），或允许客户端自己做限流（SDK 内置） |
> | 恶意攻击     | 触发多次限流后自动封 IP（加入 blocklist），上游用 Cloudflare / AWS Shield 过滤 |
>
> ------
>
> ### Deep Dive 5：动态规则配置
>
> > 如何在不重新部署代码的情况下修改限流规则？
>
> | 方案                              | 原理                               | 更新延迟   | 复杂度 |
> | --------------------------------- | ---------------------------------- | ---------- | ------ |
> | **轮询（Poll-Based）**            | Gateway 每 30 秒去数据库拉一次规则 | 最多 30 秒 | 低     |
> | **推送（Push-Based，ZooKeeper）** | 规则变化立即推送给所有 Gateway     | 秒级       | 高     |
>
> **我们选轮询**：30 秒延迟对大多数场景够用，实现简单。只有需要毫秒级响应（比如安全事件紧急封锁）才用推送。
>
> **ZooKeeper 是什么（给小白）**：一个专门做"分布式配置同步"的系统。任何节点的配置变了，它马上通知所有连接的服务。类比：WhatsApp 群消息，有人发消息，所有人实时收到。
>
> ------
>
> ## 总结：面试作答完整流程
>
> ```
> 面试官: "设计一个 Rate Limiter"
> 
> 你的回答路径:
> 1. [1分钟] 确认需求 → 功能(识别/限制/拒绝) + 非功能(低延迟/高可用/100万QPS)
> 2. [1分钟] 核心实体 → Rule / Client / Request
> 3. [30秒] 系统接口 → isRequestAllowed() 返回 allowed/remaining/resetTime
> 4. [8分钟] 高层设计:
>    ├── 放在哪? → API Gateway（对比三种方案）
>    ├── 如何识别? → UserID/IP/APIKey，多层叠加取最严
>    ├── 用什么算法? → Token Bucket（对比四种，说清楚选择原因）
>    └── 状态存哪? → Redis，解决竞态用 Lua 脚本
> 5. [10分钟] Deep Dives:
>    ├── 扩展到100万QPS → Redis Sharding + 一致性哈希
>    ├── Redis挂了 → Fail-Closed + 主从复制
>    ├── 低延迟 → 连接池 + 地理分布
>    ├── 热点 → 封 IP + DDoS 防护
>    └── 动态配置 → 轮询（30秒延迟）
> ```
>
> ------
>
> ## 🔑 面试金句（可以直接说）
>
> > "我选择 Token Bucket 算法，因为它用最小的内存（每用户仅需两个值：token 数和上次刷新时间），同时支持突发流量，这更符合真实的 API 使用模式。"
>
> > "为了保证分布式环境下的正确性，我会使用 Redis Lua 脚本将读-算-写操作合并为原子操作，消除竞态条件。"
>
> > "Redis 不可用时，我选择 Fail-Closed（拒绝所有请求），因为限流服务通常在流量高峰时失败，此时 Fail-Open 会导致后端级联崩溃，比短暂服务中断危害更大。"
>
> > "通过 Redis Cluster 的一致性哈希分片，10个分片每个处理10万QPS，合计支撑100万QPS目标。"